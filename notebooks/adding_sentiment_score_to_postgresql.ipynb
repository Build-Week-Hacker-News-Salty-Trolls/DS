{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "cwd = os.getcwd()\n",
    "sys.path[0] = cwd[:cwd.rfind('/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------- Pandas settings --------------- #\n",
    "# Removes rows and columns truncation of '...'\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Connection to Google Cloud BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_create(client, ds_ref, table_name, count=30000):\n",
    "    \"\"\"\n",
    "    Create a pandas dataframe from Google bigquery connection\n",
    "    \n",
    "    Parameters\n",
    "    ---------------------------------------------------------\n",
    "    client:       bigquery connection\n",
    "    ds_ref:       a connected bigquery dataset reference\n",
    "    table_name:   (str) name of the table\n",
    "    count:        (int) the number of rows from the table to return\n",
    "    \n",
    "    Output\n",
    "    ---------------------------------------------------------\n",
    "    Returns a pandas dataframe\n",
    "    \"\"\"\n",
    "    table_ref = ds_ref.table(table_name)\n",
    "    table = client.get_table(table_ref)\n",
    "    \n",
    "    df = client.list_rows(table, max_results=count).to_dataframe()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Cloud credentials\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '../saltyhackers-bigquery.json'\n",
    "\n",
    "# Open bigquery client connection\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Create bigquery dataset reference\n",
    "hn_ref = client.dataset('hacker_news', project='bigquery-public-data')\n",
    "\n",
    "# Get 'comments' table from bigquery\n",
    "# Create dataframe with 50000 rows\n",
    "# ElephantSQL limit it 20MB\n",
    "\n",
    "comm_df = df_create(client, hn_ref, 'comments', 50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sneak Peek at dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>by</th>\n",
       "      <th>author</th>\n",
       "      <th>time</th>\n",
       "      <th>time_ts</th>\n",
       "      <th>text</th>\n",
       "      <th>parent</th>\n",
       "      <th>deleted</th>\n",
       "      <th>dead</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2701393</td>\n",
       "      <td>5l</td>\n",
       "      <td>5l</td>\n",
       "      <td>1309184881</td>\n",
       "      <td>2011-06-27 14:28:01+00:00</td>\n",
       "      <td>And the glazier who fixed all the broken windo...</td>\n",
       "      <td>2701243</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5811403</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>1370234048</td>\n",
       "      <td>2013-06-03 04:34:08+00:00</td>\n",
       "      <td>Does canada have the equivalent of H1B/Green c...</td>\n",
       "      <td>5804452</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21623</td>\n",
       "      <td>AF</td>\n",
       "      <td>AF</td>\n",
       "      <td>1178992400</td>\n",
       "      <td>2007-05-12 17:53:20+00:00</td>\n",
       "      <td>Speaking of Rails, there are other options in ...</td>\n",
       "      <td>21611</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10159727</td>\n",
       "      <td>EA</td>\n",
       "      <td>EA</td>\n",
       "      <td>1441206574</td>\n",
       "      <td>2015-09-02 15:09:34+00:00</td>\n",
       "      <td>Humans and large livestock (and maybe even pet...</td>\n",
       "      <td>10159396</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2988424</td>\n",
       "      <td>Iv</td>\n",
       "      <td>Iv</td>\n",
       "      <td>1315853580</td>\n",
       "      <td>2011-09-12 18:53:00+00:00</td>\n",
       "      <td>I must say I reacted in the same way when I re...</td>\n",
       "      <td>2988179</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  by author        time                   time_ts  \\\n",
       "0   2701393  5l     5l  1309184881 2011-06-27 14:28:01+00:00   \n",
       "1   5811403  99     99  1370234048 2013-06-03 04:34:08+00:00   \n",
       "2     21623  AF     AF  1178992400 2007-05-12 17:53:20+00:00   \n",
       "3  10159727  EA     EA  1441206574 2015-09-02 15:09:34+00:00   \n",
       "4   2988424  Iv     Iv  1315853580 2011-09-12 18:53:00+00:00   \n",
       "\n",
       "                                                text    parent deleted  dead  \\\n",
       "0  And the glazier who fixed all the broken windo...   2701243    None  None   \n",
       "1  Does canada have the equivalent of H1B/Green c...   5804452    None  None   \n",
       "2  Speaking of Rails, there are other options in ...     21611    None  None   \n",
       "3  Humans and large livestock (and maybe even pet...  10159396    None  None   \n",
       "4  I must say I reacted in the same way when I re...   2988179    None  None   \n",
       "\n",
       "   ranking  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out Users that have less than 10 comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strangler(df):\n",
    "    \"\"\"\n",
    "    Filters out dataset to include only users who have posted _at least_\n",
    "    ten times.\n",
    "    --------------------------------------------------------------------\n",
    "    Returns : a filtered pandas dataframe\n",
    "    \n",
    "    Parameters\n",
    "    --------------------------------------------------------------------\n",
    "    df : a pandas dataframe, generated from Google Big Query\n",
    "    \"\"\"\n",
    "    \n",
    "    X = df.copy()\n",
    "    X = X.groupby('author').filter(lambda x: x['author'].count()>9)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18192, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>by</th>\n",
       "      <th>author</th>\n",
       "      <th>time</th>\n",
       "      <th>time_ts</th>\n",
       "      <th>text</th>\n",
       "      <th>parent</th>\n",
       "      <th>deleted</th>\n",
       "      <th>dead</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4895850</td>\n",
       "      <td>Mz</td>\n",
       "      <td>Mz</td>\n",
       "      <td>1355082935</td>\n",
       "      <td>2012-12-09 19:55:35+00:00</td>\n",
       "      <td>So, basically, you think I have Munchausen the...</td>\n",
       "      <td>4895812</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10313701</td>\n",
       "      <td>Mz</td>\n",
       "      <td>Mz</td>\n",
       "      <td>1443725815</td>\n",
       "      <td>2015-10-01 18:56:55+00:00</td>\n",
       "      <td>One way to test your hypothesis is to start re...</td>\n",
       "      <td>10313194</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1658291</td>\n",
       "      <td>Mz</td>\n",
       "      <td>Mz</td>\n",
       "      <td>1283476918</td>\n",
       "      <td>2010-09-03 01:21:58+00:00</td>\n",
       "      <td>And then there is always the risk that someone...</td>\n",
       "      <td>1658204</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4911653</td>\n",
       "      <td>Mz</td>\n",
       "      <td>Mz</td>\n",
       "      <td>1355336835</td>\n",
       "      <td>2012-12-12 18:27:15+00:00</td>\n",
       "      <td>Maybe you should acquaint yourself with a book...</td>\n",
       "      <td>4911595</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3996858</td>\n",
       "      <td>Mz</td>\n",
       "      <td>Mz</td>\n",
       "      <td>1337456956</td>\n",
       "      <td>2012-05-19 19:49:16+00:00</td>\n",
       "      <td>Again, I do not agree. Emotion or \"caring\" is ...</td>\n",
       "      <td>3996819</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  by author        time                   time_ts  \\\n",
       "19   4895850  Mz     Mz  1355082935 2012-12-09 19:55:35+00:00   \n",
       "20  10313701  Mz     Mz  1443725815 2015-10-01 18:56:55+00:00   \n",
       "21   1658291  Mz     Mz  1283476918 2010-09-03 01:21:58+00:00   \n",
       "22   4911653  Mz     Mz  1355336835 2012-12-12 18:27:15+00:00   \n",
       "23   3996858  Mz     Mz  1337456956 2012-05-19 19:49:16+00:00   \n",
       "\n",
       "                                                 text    parent deleted  dead  \\\n",
       "19  So, basically, you think I have Munchausen the...   4895812    None  None   \n",
       "20  One way to test your hypothesis is to start re...  10313194    None  None   \n",
       "21  And then there is always the risk that someone...   1658204    None  None   \n",
       "22  Maybe you should acquaint yourself with a book...   4911595    None  None   \n",
       "23  Again, I do not agree. Emotion or \"caring\" is ...   3996819    None  None   \n",
       "\n",
       "    ranking  \n",
       "19        0  \n",
       "20        0  \n",
       "21        0  \n",
       "22        0  \n",
       "23        0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm_df = strangler(comm_df)\n",
    "print(comm_df.shape)\n",
    "comm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping hard currency raises the bar to entry and kills a lot of low end business.  No more street vendors, cash only local business, friendly card games or bets, informal services, or convenient tips.  It would also give the plastic channel immense power over businesses.  You might not use cash very often, but dropping it altogether would not be a good idea.\n",
      "\n",
      "I'm glad you enjoyed it, but in my opinion the article was misleading. Not just simplified.I didn't go on and on in detail about systemic and random effects, linking to NIST tech reports on all the corrections they have to do on primary standards (http://tf.boulder.nist.gov/general/pdf/1846.pdf?origin=publi... on the redshift error at NISTs boulder facilities; and http://tf.boulder.nist.gov/general/pdf/2704.pdf on the sources of error in the F2 primary reference, see section 3.2 on relativistic effects), or pointing out people's amateur time keeping experiments where they demonstrate relativistic influence on decades old hardware ( http://leapsecond.com/ptti2006/tvb-project-great-ptti-ppt.pd... (this presentation is long and a ton of fun)), etc. or all the other bits of trash I could have pulled out to demonstrate knowing something here... because that wasn't my goal, the only point I was trying to make is that the article was likely to make many readers _less_ knowledgeable about the subject.(But I will give those links now, because this argument is boring and time is neat!)Perhaps you have enough background that you were not thrown off by the seeming claim that improved accuracy somehow makes these experimental references _less useful_, and you already know that relativistic effects aren't unique to optical lattice clocks and already must be compensated for, but I am sure that this is not universally the case.What I get from the article isn't nothing... Potentially I get community around me which is less informed than they started and all that entails. Perhaps that's compensated for the fun they had reading about an interesting subject? or the additional learning they do after?  I don't know, but I think the article could have been just as enjoyable without the bogus mystique that makes it misleading.But if pointing out an article was, in my opinion, potentially misleading makes me everything that is wrong about Hacker News, I'll wear that proudly.I, for one, think it's more likely the case that crappy shock headlines like \"end time as we know it\", constructed drama, and false freshness are a bigger drag on HN (and wider society) than any of my posts are likely to be... but to each his own.\n",
      "\n",
      "I'm somewhat frightened by what this could imply about our cultures. :(\n",
      "\n",
      "Training beforehand would be preferable, but I would expect a lot of improvisation going on in case of a disaster. So I see at least a chance that something useful could be improvised in terms of software.Facial recognitions sounds like a good idea, very eerie, though. I have no experience with that kind of software unfortunately.\n",
      "\n",
      "> Do you have a link that shows WoWs revenues?As far as I know, there's no such thing, only estimates based on e.g. the subscribers base. These estimates are generally in the $1bn to $1.5bn range (edit: per year), and usually on the lower end of that range, since ~2008.Which definitely does not put any given WoW year at the top of grossing movies (but still in a healthy position, 10 movies so far have gone beyond a billion gross). Still I think a fairer comparison would be to movie franchises, if we put WoW's total revenue around 5~6bn it would rank #2 behind the Harry Potter franchise ($7.7bn) and before James Bond ($5.1bn).However, I think it's fair to say WoW is an anomaly in terms of revenue. Even more so than billion-grossing movies.\n",
      "\n",
      "Which is interesting, as a proper regular expression is incapable of testing for a parens match. The set of strings with properly matched parens is a context-free language, not a regular language. But modern \"regex\" engines are capable of matching non-regular languages, and iterative regex-based substitutions (as his client-side code does--his server-side code is equivalent to the stack-based approach) can approximate the effect.\n",
      "\n",
      "Hasn't Java had a JIT compiling VM for a while now? And in the times I've used it, it has certainly seemed statically typed and compiled (to Java bytecode) to me.\n",
      "\n",
      "That's a point a lot of people miss; redistribution of wealth to maintain acceptable levels of inequality are what maintain the peace.  It doesn't matter if redistribution of wealth is right or wrong, only that it's a practical necessity to maintain a stable society.\n",
      "\n",
      "Most people don't smell bad after 5 minutes of mild exercise in an air conditioned building.  Just saying.\n",
      "\n",
      ">better option than the 'professional' option of passive-aggressive removal of commit privelegesActually, the move Linus chose seems pretty \"professional\" in the \"this is pretty good management\" sense:- The error was made public so that it won't be repeated- The exposition was done in such a way to understand exactly how much he doesn't want this to happen againThe \"calling it out in front of everybody\" thing is.... I don't know how necessary/unnecessary that is. But he doesn't attack the person, he attacked the issue. That's the essential\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import html\n",
    "\n",
    "\n",
    "def cleanup_html(raw_html):\n",
    "    \"\"\"\n",
    "    Clean's up raw HTML code to proper format\n",
    "    \"\"\"\n",
    "    clean_html = re.sub(r'<.*?>', '', raw_html)\n",
    "    clean_html_http = re.sub(r'http\\S+([\\.]{3})?', '', clean_html)\n",
    "    clean_txt = html.unescape(clean_html)\n",
    "    return clean_txt\n",
    "\n",
    "# Apply the function\n",
    "comm_df['text'] = comm_df['text'].apply(cleanup_html)\n",
    "\n",
    "# Check results\n",
    "comm_df.sample(10)\n",
    "\n",
    "for row in comm_df['text'].sample(10):\n",
    "    print(row)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing ML on our dataframe\n",
    "\n",
    "\n",
    "### Vader Sentimental Analysis\n",
    "\n",
    "According to Urban Dictionary, a salty person is someone that’s bitter (kinda weird since bitter and salty are completely different tastes, but the transformation of the English language is a topic for another day). Can we predict which users of Hacker News are the saltiest/most toxic based on the comments they post? Can we help users identify whose comments on Hacker News to ignore in order to make their time on the site more enjoyable? How will we determine what “salty” means?\n",
    "\n",
    "For this sentiment analysis model, we will use Vader Sentiment due to its simplicity and ability to handle text typically found on social media (robust measures regarding slang, capitalized letters, emojis, and punctuation). In order to determine a user's \"saltiness\", we will utilize 3 of Vader's polarity scores: positivity, compound, and negative. Positive and negative scores are self-explanatory; however, the compound score is worth understanding further. According to the Vader Sentiment documentation:\n",
    "\n",
    "    The compound score is computed by summing the valence scores of each word in the lexicon, adjusted according to the rules, and then normalized to be between -1 (most extreme negative) and +1 (most extreme positive). This is the most useful metric if you want a single unidimensional measure of sentiment for a given sentence. Calling it a 'normalized, weighted composite score' is accurate.\n",
    "\n",
    "Furthermore, the documentation breaks down how sentiment is obtained:\n",
    "\n",
    "    Typical threshold values (used in the literature cited on this page) are:\n",
    "\n",
    "    positive sentiment: compound score >= 0.05\n",
    "    neutral sentiment: (compound score > -0.05) and (compound score < 0.05)\n",
    "    negative sentiment: compound score <= -0.05\n",
    "\n",
    "    The pos, neu, and neg scores are ratios for proportions of text that fall in each category (so these should all add up to be 1... or close to it with float operation). These are the most useful metrics if you want multidimensional measures of sentiment for a given sentence.\n",
    "\n",
    "With this understanding, we can now derive a formula to determine the saltiness of our users' comments. For our purposes, we want to give a bit more weight to the positive and negative ratios, so we will define our score formula as follows:\n",
    "\n",
    "    **Saltiness Score** = *Positive Ratio* + *Compound Score* - *Negative Ratio*\n",
    "\n",
    "\n",
    "We only need to perform sentiment analysis on the users' comments, so we'll only focus on the 'text' column. The goal here is to perform an analysis on each comment, and append the comment's score to a corresponding 'score' column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the sentiment analysis function\n",
    "\n",
    "def sentiment_score(comment):\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    x = 0\n",
    "    score = analyser.polarity_scores(comment)\n",
    "    x = x + score['pos']\n",
    "    x = x + score['compound']\n",
    "    x = x - score['neg'] \n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each sample in the 'text' column\n",
    "# Store score in newly-created 'score' column\n",
    "comm_df['salty_score'] = comm_df['text'].apply(sentiment_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>by</th>\n",
       "      <th>author</th>\n",
       "      <th>time</th>\n",
       "      <th>time_ts</th>\n",
       "      <th>text</th>\n",
       "      <th>parent</th>\n",
       "      <th>deleted</th>\n",
       "      <th>dead</th>\n",
       "      <th>ranking</th>\n",
       "      <th>salty_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4895850</td>\n",
       "      <td>Mz</td>\n",
       "      <td>Mz</td>\n",
       "      <td>1355082935</td>\n",
       "      <td>2012-12-09 19:55:35+00:00</td>\n",
       "      <td>So, basically, you think I have Munchausen the...</td>\n",
       "      <td>4895812</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10313701</td>\n",
       "      <td>Mz</td>\n",
       "      <td>Mz</td>\n",
       "      <td>1443725815</td>\n",
       "      <td>2015-10-01 18:56:55+00:00</td>\n",
       "      <td>One way to test your hypothesis is to start re...</td>\n",
       "      <td>10313194</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1658291</td>\n",
       "      <td>Mz</td>\n",
       "      <td>Mz</td>\n",
       "      <td>1283476918</td>\n",
       "      <td>2010-09-03 01:21:58+00:00</td>\n",
       "      <td>And then there is always the risk that someone...</td>\n",
       "      <td>1658204</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4911653</td>\n",
       "      <td>Mz</td>\n",
       "      <td>Mz</td>\n",
       "      <td>1355336835</td>\n",
       "      <td>2012-12-12 18:27:15+00:00</td>\n",
       "      <td>Maybe you should acquaint yourself with a book...</td>\n",
       "      <td>4911595</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.7495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3996858</td>\n",
       "      <td>Mz</td>\n",
       "      <td>Mz</td>\n",
       "      <td>1337456956</td>\n",
       "      <td>2012-05-19 19:49:16+00:00</td>\n",
       "      <td>Again, I do not agree. Emotion or \"caring\" is ...</td>\n",
       "      <td>3996819</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  by author        time                   time_ts  \\\n",
       "19   4895850  Mz     Mz  1355082935 2012-12-09 19:55:35+00:00   \n",
       "20  10313701  Mz     Mz  1443725815 2015-10-01 18:56:55+00:00   \n",
       "21   1658291  Mz     Mz  1283476918 2010-09-03 01:21:58+00:00   \n",
       "22   4911653  Mz     Mz  1355336835 2012-12-12 18:27:15+00:00   \n",
       "23   3996858  Mz     Mz  1337456956 2012-05-19 19:49:16+00:00   \n",
       "\n",
       "                                                 text    parent deleted  dead  \\\n",
       "19  So, basically, you think I have Munchausen the...   4895812    None  None   \n",
       "20  One way to test your hypothesis is to start re...  10313194    None  None   \n",
       "21  And then there is always the risk that someone...   1658204    None  None   \n",
       "22  Maybe you should acquaint yourself with a book...   4911595    None  None   \n",
       "23  Again, I do not agree. Emotion or \"caring\" is ...   3996819    None  None   \n",
       "\n",
       "    ranking  salty_score  \n",
       "19        0       0.3522  \n",
       "20        0       0.1742  \n",
       "21        0      -0.3362  \n",
       "22        0      -0.7495  \n",
       "23        0       0.9407  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check results\n",
    "comm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rank(df):\n",
    "    \n",
    "    # Create separate dataframe based on user overall rank\n",
    "    # Reset index twice to get new numeric column\n",
    "    rank_df = df.groupby('author')['salty_score'].sum().sort_values(ascending=True).reset_index().reset_index()\n",
    "    \n",
    "    # Add 1 to get the rank\n",
    "    rank_df['index'] = rank_df['index'] + 1\n",
    "    \n",
    "    # Wrangle the rank_df\n",
    "    rank_df = rank_df[['index', 'author']]\n",
    "    \n",
    "    # Change the rank_df column names\n",
    "    rank_df.columns = ['ranking', 'author']\n",
    "    \n",
    "    # Left merge rank_df with original df on 'author' column\n",
    "    merged = pd.merge(df, rank_df, how='left', on='author')\n",
    "    \n",
    "    # Wrangle merged dataframe\n",
    "    merged = merged.drop(columns=['ranking_x', 'deleted', 'dead'])\n",
    "    \n",
    "    # Rename columns\n",
    "    merged.columns = ['id', 'by', 'author', 'time', 'time_ts', \n",
    "                      'text', 'parent', 'salty_score', 'ranking']\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>by</th>\n",
       "      <th>author</th>\n",
       "      <th>time</th>\n",
       "      <th>time_ts</th>\n",
       "      <th>text</th>\n",
       "      <th>parent</th>\n",
       "      <th>salty_score</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4895850</td>\n",
       "      <td>Mz</td>\n",
       "      <td>Mz</td>\n",
       "      <td>1355082935</td>\n",
       "      <td>2012-12-09 19:55:35+00:00</td>\n",
       "      <td>So, basically, you think I have Munchausen the...</td>\n",
       "      <td>4895812</td>\n",
       "      <td>0.3522</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10313701</td>\n",
       "      <td>Mz</td>\n",
       "      <td>Mz</td>\n",
       "      <td>1443725815</td>\n",
       "      <td>2015-10-01 18:56:55+00:00</td>\n",
       "      <td>One way to test your hypothesis is to start re...</td>\n",
       "      <td>10313194</td>\n",
       "      <td>0.1742</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1658291</td>\n",
       "      <td>Mz</td>\n",
       "      <td>Mz</td>\n",
       "      <td>1283476918</td>\n",
       "      <td>2010-09-03 01:21:58+00:00</td>\n",
       "      <td>And then there is always the risk that someone...</td>\n",
       "      <td>1658204</td>\n",
       "      <td>-0.3362</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4911653</td>\n",
       "      <td>Mz</td>\n",
       "      <td>Mz</td>\n",
       "      <td>1355336835</td>\n",
       "      <td>2012-12-12 18:27:15+00:00</td>\n",
       "      <td>Maybe you should acquaint yourself with a book...</td>\n",
       "      <td>4911595</td>\n",
       "      <td>-0.7495</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3996858</td>\n",
       "      <td>Mz</td>\n",
       "      <td>Mz</td>\n",
       "      <td>1337456956</td>\n",
       "      <td>2012-05-19 19:49:16+00:00</td>\n",
       "      <td>Again, I do not agree. Emotion or \"caring\" is ...</td>\n",
       "      <td>3996819</td>\n",
       "      <td>0.9407</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  by author        time                   time_ts  \\\n",
       "0   4895850  Mz     Mz  1355082935 2012-12-09 19:55:35+00:00   \n",
       "1  10313701  Mz     Mz  1443725815 2015-10-01 18:56:55+00:00   \n",
       "2   1658291  Mz     Mz  1283476918 2010-09-03 01:21:58+00:00   \n",
       "3   4911653  Mz     Mz  1355336835 2012-12-12 18:27:15+00:00   \n",
       "4   3996858  Mz     Mz  1337456956 2012-05-19 19:49:16+00:00   \n",
       "\n",
       "                                                text    parent  salty_score  \\\n",
       "0  So, basically, you think I have Munchausen the...   4895812       0.3522   \n",
       "1  One way to test your hypothesis is to start re...  10313194       0.1742   \n",
       "2  And then there is always the risk that someone...   1658204      -0.3362   \n",
       "3  Maybe you should acquaint yourself with a book...   4911595      -0.7495   \n",
       "4  Again, I do not agree. Emotion or \"caring\" is ...   3996819       0.9407   \n",
       "\n",
       "   ranking  \n",
       "0      670  \n",
       "1      670  \n",
       "2      670  \n",
       "3      670  \n",
       "4      670  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm_df = add_rank(comm_df)\n",
    "comm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pushing the dataframe to postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all we have left to do is convert our pandas dataframe to SQL and load it into our postgres database. For this project, we chose to employ the help of ElephantSQL for its simple interface and exceptional DBMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_postgres(df, title, engine):\n",
    "    \"\"\"\n",
    "    Migrate pandas dataframe to postgresql database.\n",
    "    \n",
    "    Only works with SQLAlchemy or sqlite.\n",
    "    \n",
    "    For reference:\n",
    "    https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.DataFrame.to_sql.html\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ---------------------------------------------------------\n",
    "    df: a pandas dataframe\n",
    "    title (str): what you want to call the SQL table\n",
    "    engine: the sql engine/connection you established\n",
    "    \n",
    "    Output\n",
    "    ---------------------------------------------------------\n",
    "    Returns nothing. Check to see if you can query the \n",
    "    database using SQLAlchemy in python.\n",
    "    \"\"\"\n",
    "    df.to_sql(title, engine, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "# Establish connection to database\n",
    "engine = create_engine('postgres://txtqhcho:mHEV5Or0MiRw_5oaIJF162BkmqapzanU@salt.db.elephantsql.com:5432/txtqhcho')\n",
    "\n",
    "# Covert dataframe to SQL\n",
    "to_postgres(comm_df, 'salt', engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
